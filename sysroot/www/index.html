<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!--script src="https://wzrd.in/standalone/h264-converter@latest"></script-->
    <script src="https://unpkg.com/jpeg-asm@1.0.0/dist/jpegasm.js"></script>
    <style>
        .slidecontainer {
          width: 100%; /* Width of the outside container */
        }

        /* The slider itself */
        .slider {
          -webkit-appearance: none;  /* Override default CSS styles */
          appearance: none;
          width: 640px; /* Full-width */
          height: 25px; /* Specified height */
          background: #d3d3d3; /* Grey background */
          outline: none; /* Remove outline */
          opacity: 0.7; /* Set transparency (for mouse-over effects on hover) */
          -webkit-transition: .2s; /* 0.2 seconds transition on hover */
          transition: opacity .2s;
        }

        /* Mouse-over effects */
        .slider:hover {
          opacity: 1; /* Fully shown on mouse-over */
        }

        /* The slider handle (use -webkit- (Chrome, Opera, Safari, Edge) and -moz- (Firefox) to override default look) */
        .slider::-webkit-slider-thumb {
          -webkit-appearance: none; /* Override default look */
          appearance: none;
          width: 25px; /* Set a specific slider handle width */
          height: 25px; /* Slider handle height */
          background: #4CAF50; /* Green background */
          cursor: pointer; /* Cursor on hover */
        }

        .slider::-moz-range-thumb {
          width: 25px; /* Set a specific slider handle width */
          height: 25px; /* Slider handle height */
          background: #4CAF50; /* Green background */
          cursor: pointer; /* Cursor on hover */
        }
    </style>
    <title>SmartPi LiveStream</title>
</head>
<body>

<!--video controls width="640px" height="480px" id="smartpi_stream"></video-->
<div>
<canvas width="640px" height="480px" style="border:black;" id="smartpi_stream"></canvas>

<div class="slidecontainer" width="640px">
    <input type="range" width="640px" min="1" max="100" value="50" class="slider" id="myRange" />
</div>
<input type="checkbox" id="lock_frame">锁定帧率：强行以接收帧率播放视频，这会增加实时性，但是会造成视觉效果的不连贯</input>
<br/>
<input type="checkbox" id="lazy">惰性模式：在没有运动的时候自动暂停视频</input><br/>敏感度：<br/><input type="range"  min="10" max="100000" value="10000" class="slider" id="sensitivity" />
<br/>
<input type="checkbox" id="details" checked="true">显示FPS等信息</input>
<br/>
<a href id="download">下载录制的视频</a>
<p id="frame_time"></p>
<p id="frame_latency"></p>
<p id="frame_infer_latency"></p>
<p id="frame_fps"></p>
<p id="frame_remote_fps"></p>
<p id="frame_predict"></p>
</div>
</body>

<script type="text/javascript">

	let frame_time=document.getElementById("frame_time");
	let frame_latency=document.getElementById("frame_latency");
	let frame_infer_latency=document.getElementById("frame_infer_latency");
	let frame_fps=document.getElementById("frame_fps");
	let frame_remote_fps=document.getElementById("frame_remote_fps");
	let frame_predict=document.getElementById("frame_predict");
    //require.cache.expire = 100000;
    let progbar=document.getElementById('myRange');
	let sensitivity=document.getElementById('sensitivity');
     let progress=0;
	 let lock_frame=document.getElementById("lock_frame");
	let lazy=document.getElementById("lazy");
	let details=document.getElementById("details");
     progbar.addEventListener("input", function(ev) {
     //console.log(progbar.min, progbar.max, progbar.value, ev.value);
        progress=progbar.value;
		lock_frame.checked=false;
		lazy.checked=false;
     });
	
    async function main(){

        //let VideoConverter=h264Converter.default;
        //h264Converter.setLogger(console.log, console.err);
        let elem=document.getElementById('smartpi_stream');
        let ctx = elem.getContext("2d", {"alpha": false});
        ctx.imageSmoothingEnabled= false;
        //const converter=new VideoConverter(elem, 60, 10);
		let vid=document.getElementById('vid');
		let stream=elem.captureStream(60);
		let recorder=new MediaRecorder(stream, {mimeType: 'video/webm;codecs=vp9'});
		
		
		//vid.srcObject=stream;
		//vid.play()
        let socket = new WebSocket("ws://10.114.51.1:17000");
        socket.binaryType = 'arraybuffer';
        function getUint64(dataview, byteOffset, littleEndian) {
          // split 64-bit number into two 32-bit (4-byte) parts
          const left =  dataview.getUint32(byteOffset, littleEndian);
          const right = dataview.getUint32(byteOffset+4, littleEndian);

          // combine the two 32-bit values
          const combined = littleEndian? left + 2**32*right : 2**32*left + right;

          if (!Number.isSafeInteger(combined))
            console.warn(combined, 'exceeds MAX_SAFE_INTEGER. Precision may be lost');

          return combined;
        }
        let framequeue=[];

        async function request_frame(frame){
            const buffer=new ArrayBuffer(9);

            const view=new DataView(buffer);
            view.setUint8(0, 0x1);
            view.setBigUint64(1, BigInt(frame), true);
            //console.log(buffer);
            socket.send(buffer);
        }

        let frames=[];
        window.offset=0;
        //window.tags=tags;
        window.frames=frames;




        let rendered_frames=0;
        let t0 = performance.now();
        let SIZE=24;
        ctx.font =SIZE+'px Arial';
        ctx.fillStyle = "red";
        function parsetag(tag){
            if(tag==0) return "无"
            else if(tag==1) return "布"
            else if(tag==2) return "剪刀"
            else return "石头"
        }
        let received_frames=0;
        let receive_t=performance.now();
		let lazy_counter=0;
		let lazy_image=null;
		let lazy_frame=null;
		let lazy_play=250;
        async function raf_refresh(){
            //console.log(`${progress}/${offset+frames.length-1}`)
			
            let f=null;
			if(lock_frame.checked || lazy.checked){
				progress=offset+frames.length-1;
			}
            if(progress>=(offset+frames.length-1)){
                if(frames[progress-offset]){
                    f=await frames[progress-offset];

                }else{

                }
            }else{
                f=await frames[progress-offset];
                //console.log(new Date(capture_time))

                progress++;
            }
			lazy_counter++;
			if(lazy_counter%50==0){
				let last_f=await frames[frames.length-1];
				let pixels=jpegasm.decode(last_f.slice)
				pixels=new Uint8Array(pixels.buffer)
				if(lazy_image){
					//console.log("Lazy!", pixels);
					let error=0;
					for(let i=0; i<pixels.length; i++){
						let delta=(pixels[i]-lazy_image[i])/255.0;
						error+=delta*delta;
					}
					//console.log(error);
					let sense=sensitivity.value;
					if(error>sense) console.error(error);
					else console.warn(error);
					if(error>sense) lazy_play=250;
					
				}else{
					
				}
				lazy_image=pixels;
				lazy_frame=last_f;
				lazy_counter=0;
			}
			if(lazy.checked){
				if(lazy_play){
					lazy_play--;
				}else{
					f=lazy_frame;
				}
			}
            if(f){

                let {img, capture_time, infer_time, tag}=f;
                ctx.drawImage(img, 0, 0);
                //ctx.drawImage(img["canvas"], 0, img["offset"]*480, 640, 480, 0, 0, 640, 480);
				let t1=performance.now()-t0;
					let t2=performance.now()-receive_t;
					let details_arr=[new Date(capture_time), `Latency: ${new Date()-new Date(capture_time)}ms ${"S="+sensitivity.value+(lazy.checked && lazy_play==0?"(Pause)":"")}`, `Infer latency: ${infer_time-capture_time}ms`, `FPS: ${rendered_frames/(t1/1000)}`,`(Remote: ${received_frames*10/t2*1000})`, `Predict: ${parsetag(tag)}`]
				if(details.checked){
					
					ctx.fillText(details_arr[0],  10, SIZE);
					ctx.fillText(details_arr[1],  10, SIZE*2);
					ctx.fillText(details_arr[2], 10, SIZE*3)
					
					ctx.fillText(details_arr[3], 10, SIZE*4)
					ctx.fillText(details_arr[4], 10, SIZE*5)
					ctx.fillText(details_arr[5], 10, SIZE*6)
					
					
				}frame_time.innerHTML=details_arr.join("<br/>")
                //console.log(tag);
            }
            rendered_frames++;
            progbar.min=offset;
            progbar.max=offset+frames.length-1;
            progbar.value=progress;
            if(rendered_frames%100==0){

                //console.log(`${progress}/${offset+frames.length-1} FPS=${rendered_frames/(t1/1000)}`);
            }

            window.requestAnimationFrame(raf_refresh);
        }


        window.requestAnimationFrame(raf_refresh);

        socket.onmessage=function(e){
            const message=e.data;
            const view=new DataView(message);
            let len=view.byteLength;
            let type=view.getUint8(len-1);
            if(type==0){
                let a=getUint64(view, 0, true);
                let b=getUint64(view, 8, true);
                //console.log(a, b);
                let header=message.slice(16, len-1);
                //console.log(header);
                try{
                    //converter.appendRawData(new Uint8Array(header));
                }catch(err){
                    console.log(err);
                }
                offset=(b-2)*10;
                progress=offset;
                framequeue.push(b-2);
                request_frame(b-2);
            }else if(type==1){
                let i=framequeue.shift();
                console.log("frame "+i+" fetched!");

                let offset=320;
                let sizes=[];
                let capture_times=[];
                let infer_times=[];
                let tags=[];
                for(let i=0; i<10; i++){
                    let size=getUint64(view, i*32, true);
                    let capture_time=getUint64(view, i*32+8, true);
                    let infer_time=getUint64(view, i*32+16, true);
                    let frame_tag=getUint64(view, i*32+24, true);
                    sizes.push(size);
                    capture_times.push(capture_time);
                    infer_times.push(infer_time);
                    tags.push(frame_tag);
                }
                /*
                let imgdata=new ImageData(640, 4800);
                let d=imgdata.data;
                let j=0;

                for(let i=0; i<640*480*10; i++){
                    d[j]=message[offset+j];
                    d[j+1]=message[offset+j+1];
                    d[j+2]=message[offset+j+2];
                    d[j+3]=255;
                    j+=4;
                }
                let osc=new OffscreenCanvas(640, 4800);
                let osctx=osc.getContext("2d", {"alpha": false});
                osctx.imageSmoothingEnabled= false;
                osctx.putImageData(imgdata,0,0);
                console.log(imgdata);
                */

                for(let i=0; i<10; i++){
                    let frame=message.slice(offset, offset+sizes[i]);
                    offset+=sizes[i];
                    //let jpeg=jpegasm.decode(frame,true);
                    //let old_buffer=new Uint8Array(jpeg.buffer);
                    let frame_img=new Promise((resolve, rejected)=>{
                        let ct=capture_times[i];
                        let it=infer_times[i];
                        let tg=tags[i];
                        //resolve({
                        //    "img":{
                        //        "canvas": osc,
                        //        "offset": i
                        //    }, "capture_time": ct, "infer_time": it, "tag": tg
                        //})


                        const blob=new Blob([frame], {"type": "image/jpeg"});
                        const url=URL.createObjectURL(blob);
                        const img=new Image();
                        img.onload=()=>{
                            URL.revokeObjectURL(url);
                            resolve({"img": img, "capture_time": ct, "infer_time": it, "tag": tg, "slice": frame});
                        }
                        img.onerror=(err)=>{
                            console.log("error!", err);
                        }
                        img.src=url;

                    })
                    //console.log(new_buffer);
                    frames.push(frame_img);
                    if(frames.length>60*60){
                        frames.shift();
						window.offset++;
						if(progress<window.offset) progress=window.offset;
                        //tags.shift();
                    }

                }

                received_frames++;
                if(received_frames%10==0){
                    let t=performance.now()-receive_t;
                    console.log(`recv fps=${received_frames*10/t*1000}`)
                }
                console.log("Requesting frame "+(i+1));
                framequeue.push(i+1);
                request_frame(i+1);
            }else if(type==2){
                let i=framequeue.shift();
                let a=getUint64(view, 0, true);
                let b=getUint64(view, 8, true);
                //console.log("frame "+i+` failed! (${a}, ${b})`);
                if(framequeue.length==0){
                    setTimeout(()=>{
                        framequeue.push(i);
                        request_frame(i);
                    }, 10)
                }

            }
        }
        //converter.play();
		chunks=[]
		document.getElementById("download").onclick=function(ev){
			ev.preventDefault();
			recorder.stop()
		}
		recorder.ondataavailable = function(e) {
			//console.log(e);
			chunks.push(e.data);
		}
		recorder.onstop=function(e){
			let blob = new Blob(chunks);
			chunks = [];
			let videoURL = window.URL.createObjectURL(blob);
			const link = document.createElement('a');
			link.style.display = 'none';
			link.href=videoURL;
			link.download="media.mp4"
			document.body.appendChild(link)
			link.click();
			link.remove();
			//window.location=(audioURL)
		}
		
		recorder.start(10)
		console.log(recorder.state);
    }
    main()
</script>
</html>